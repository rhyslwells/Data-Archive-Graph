{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2512f3",
   "metadata": {},
   "source": [
    "Enhance vault_index.json by adding topics to it using lda, similar to how TFIDF worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933449e",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (LDA) (Explore further)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "This code is performing topic modeling using the Latent Dirichlet Allocation (LDA) algorithm, a popular method for discovering hidden topics in a set of documents. Here’s a step-by-step breakdown of what’s happening:\n",
    "\n",
    "1. Goal:\n",
    "The objective of this code is to discover hidden topics within the documents, i.e., it tries to identify clusters of words that often appear together across the documents and group them into topics.\n",
    "\n",
    "2. Latent Dirichlet Allocation (LDA):\n",
    "LDA is a generative probabilistic model that assumes each document is a mixture of topics, and each topic is a distribution over words.\n",
    "\n",
    "The LDA model tries to find a set of topics that best explain the observed documents in terms of word distribution.\n",
    "\n",
    "\n",
    "# Goal: Discover hidden topics within the documents.\n",
    "# Technique: Latent Dirichlet Allocation (LDA) or Non-negative Matrix Factorization \n",
    "# (NMF) are common methods for topic modeling.\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Get the list of terms in the same order as the columns in the matrix X\n",
    "index_to_term = {idx: term for term, idx in term_to_index.items()}\n",
    "\n",
    "# Now, fit the LDA model to find topics\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda_topics = lda.fit_transform(X)\n",
    "\n",
    "# Print top words for each topic\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {idx}:\")\n",
    "    # Get the top 10 words for this topic\n",
    "    top_terms_idx = topic.argsort()[:-11:-1]  # Get the indices of the top 10 words\n",
    "    top_terms = [index_to_term[i] for i in top_terms_idx]\n",
    "    print(top_terms)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
