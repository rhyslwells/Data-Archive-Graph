{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3ef03b",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "- Building on graph.ipynb\n",
    "- In TFIDF_explore.ipynb we build a vector embedding using TF-IDF keys. \n",
    "We then are ableto query with non- TF-IDF keys and get documenets \n",
    "that contain similar TF-IDF keys (See Vector Search).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8104f",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "\n",
    "This notebook is designed to explore search functionality:\n",
    "\n",
    "1. Investigate existing tag usage\n",
    "2. Assess semantic-structural alignment\n",
    "3. Suggest or refine tags\n",
    "4. Visualize the graph interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76635678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Load JSON\n",
    "with open(\"Data/enhanced_vault_index.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Inspect str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd73731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1. Tag Suggestion (based on TF-IDF)\n",
    "For notes with empty `tags`, you can suggest tags based on the top terms in the `TFIDF_Score`, matched against:\n",
    "- A predefined list of possible tags (taxonomy)\n",
    "    - Get the set of unique tags from all notes\n",
    "- Tags already present in other notes\n",
    "- Embeddings from representative tag examples\n",
    "\n",
    "#### 2. Clustering / Thematic Grouping\n",
    "Cluster notes using:\n",
    "- Top N TF-IDF terms\n",
    "- Outlink/inlink patterns (graph-based community detection)\n",
    "- Embedding similarity (if you add vector representations)\n",
    "\n",
    "\n",
    "#### 4. Relevance Scoring\n",
    "You can assess how relevant a note is to a topic, query, or tag by computing overlap in TF-IDF keywords.\n",
    "- if given a text I want to be given the top 5 notes that are most relevant to it.\n",
    "- if given a text i want the top tags that are most relevant to it.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”§ Would You Like Help With?\n",
    "Let me ask a few exploratory questions to scope the next steps:\n",
    "\n",
    "1. Do you want to automatically suggest tags for notes with empty `tags`?\n",
    "   - If so, do you have a controlled vocabulary or master tag list?\n",
    "        - I have a master tag list that i would like to Use\n",
    "\n",
    "2. Are you interested in building a graph or UI from this JSON file (e.g., visualizing clusters or navigation)?\n",
    "- yes if it is easy to do so.\n",
    "\n",
    "3. Do you plan to incorporate semantic embeddings (e.g., from OpenAI, Sentence-BERT)?\n",
    "   - This would enhance clustering, grouping, and tag inference.\n",
    "    - yes\n",
    "\n",
    "4. Should we consider alias/summary/TF-IDF terms in tag suggestions, or only TF-IDF?\n",
    "    - use tfidf and tags of other notes\n",
    "\n",
    "5. Do you want to track which TF-IDF words are not yet used in your tag set, to enrich your tag vocabulary?\n",
    "\n",
    "---\n",
    "\n",
    "Let me know your priority goal (e.g., tag suggestion, clustering, visualization)\n",
    "\n",
    "Let me know your priority goal visualization\n",
    "\n",
    "priority goal clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f31cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "I am investigating a folder of documenets. I have created a JSON file where each item is the metadata for a document. I use this JSON to generate a graph.\n",
    "\n",
    "I am interested in exploring the graph relationships between the notes.\n",
    "\n",
    "I have used TF-IDF to extract the most important words from each document and added them to the JSON file.\n",
    "\n",
    "I am looking for ways to explore semantic relationships between the notes.\n",
    "\n",
    "Thank you, that clarifies things. It sounds like you're working with a semantically annotated graph where the tags represent *soft* or *semantic groupings*, and you're interested in:\n",
    "\n",
    "1. Assessing the quality or relevance of existing tags,  \n",
    "2. Suggesting better or more consistent tags, and  \n",
    "3. Possibly inferring new groupings from the graph structure.\n",
    "\n",
    "Let's break this down into a structured exploratory and modeling approach.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Explore Existing Tags\n",
    "### A. Tag Frequency & Distribution\n",
    "- Count how many nodes are associated with each tag.\n",
    "- Measure tag co-occurrence: which tags often appear together?\n",
    "\n",
    "Example: Build a tagâ€“tag co-occurrence matrix (rows and columns are tags, cell values are how often they co-occur).\n",
    "\n",
    "### B. Tag Purity / Consistency\n",
    "For each tag:\n",
    "- Do the nodes it labels have similar graph structural properties?\n",
    "  - E.g., similar in/out-degree, common neighbors?\n",
    "- Are nodes with the same tag closely connected in the graph?\n",
    "\n",
    "Metric idea:  \n",
    "For each tag, compute the average pairwise shortest path between nodes sharing that tag. Lower values suggest structural closeness.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Structural-Semantic Alignment\n",
    "### A. Community Detection vs Tag Grouping\n",
    "- Run community detection (e.g., Louvain, label propagation).\n",
    "- Compare resulting communities with tags using:\n",
    "  - Adjusted Rand Index (ARI)\n",
    "  - Normalized Mutual Information (NMI)\n",
    "  - Purity\n",
    "\n",
    "This tells you how well the tags reflect structural clusters.\n",
    "\n",
    "### B. Embedding the Graph\n",
    "Use `node2vec` or `GraphSAGE` to create embeddings of nodes based on structure.\n",
    "- Cluster embeddings (e.g., k-means, DBSCAN).\n",
    "- Compare those clusters to tags.\n",
    "\n",
    "This captures latent similarity beyond direct connections.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Suggesting / Recommending Tags\n",
    "You can treat this as a multi-label classification problem:\n",
    "- Input: Node features (degree, neighbors, tag co-occurrence, etc.)\n",
    "- Output: Tags\n",
    "\n",
    "### Feature engineering ideas:\n",
    "- Node degree\n",
    "- Embedding vector\n",
    "- Aggregated tag distribution of neighbors\n",
    "- Clustering label (from structural embedding)\n",
    "\n",
    "Train a classifier (e.g., Random Forest, Logistic Regression, or a simple MLP).\n",
    "\n",
    "Alternatively: Nearest neighbors in embedding space  \n",
    "- Recommend tags from nearest neighbors based on shared tags.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Visual Exploration\n",
    "Create an interactive graph where:\n",
    "- Nodes are colored by tag\n",
    "- Option to highlight nodes with missing or low-confidence tags\n",
    "- Use layout (e.g., Force-directed) to show proximity\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Next Steps (Optional): Refinement + Feedback Loop\n",
    "If you can validate tag suggestions (manually or semi-automatically), you can:\n",
    "- Iteratively retrain your tag recommender\n",
    "- Promote tag consistency and reduce noise\n",
    "\n",
    "---\n",
    "\n",
    "Would you like to:\n",
    "- See code to construct tag co-occurrence and tag distance metrics?\n",
    "- Build a node2vec-based embedding pipeline for clustering or tag suggestion?\n",
    "- Visualise tags on the graph with node color and interactivity?\n",
    "\n",
    "Feel free to share a small sample of the JSON so I can tailor examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a26655",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa81d5c",
   "metadata": {},
   "source": [
    "### Summary of Workflow\n",
    "\n",
    "A semantic search system over the Data Archive using a combination of:\n",
    "\n",
    "1. TF-IDF-derived term selection  \n",
    "   Each note is represented not by its full text but by a set of high-importance terms extracted from its `TFIDF_Score` dictionary.\n",
    "\n",
    "2. Sentence embedding of pseudo-texts  \n",
    "   These sets of terms are joined into a string (pseudo-text) and passed to a pretrained SentenceTransformer model to produce dense vector embeddings. This allows for semantic comparison even though the input is not natural language.\n",
    "\n",
    "3. Vector indexing with FAISS  \n",
    "   The resulting embedding vectors are added to a FAISS index, enabling fast nearest-neighbor search for concept similarity. Queries like `\"Uncertainty quantification\"` can be semantically matched against your notes.\n",
    "\n",
    "### Purpose\n",
    "\n",
    "This approach allows you to:\n",
    "- Search your notes by concept, not exact keyword match.\n",
    "- Leverage the structure of your vault (via TF-IDF scores) while benefiting from modern NLP embeddings.\n",
    "- Build a scalable semantic retrieval tool across many notes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df07d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RhysL\\Desktop\\Data-Archive-Graph\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08148919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the vault\n",
    "with open(\"../Data/enhanced_vault_index.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    vault = json.load(f)\n",
    "\n",
    "titles = list(vault.keys())\n",
    "\n",
    "texts = [\n",
    "    \" \".join(sorted(vault[title].get(\"TFIDF_Score\", {}).keys()))\n",
    "    for title in titles\n",
    "]\n",
    "# Step 3: Load sentence embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 4: Generate embeddings from the TF-IDF term keys\n",
    "embeddings = model.encode(texts, convert_to_numpy=True).astype(\"float32\")\n",
    "\n",
    "# Step 5: Build FAISS index (exact L2 search)\n",
    "dimension = embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb5b674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts\n",
    "#['action add directional discus discussion name needed person topic update',\n",
    "#  'app like method performance product testing two version',...]\n",
    "# it might be better to use LDA topic modeling here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "509cd6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar notes to 'patterns of ideas':\n",
      "\n",
      "1. Knowledge Work\n",
      "2. Data Science\n",
      "3. Thinking Systems\n",
      "4. inference\n",
      "5. MNIST\n",
      "6. Data Analysis\n",
      "7. inference versus prediction\n",
      "8. Over parameterised models\n",
      "9. Time Series Identify Trends and Patterns\n",
      "10. Scientific Method\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Semantic search with query\n",
    "query = \"patterns of ideas\"\n",
    "query_vec = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "k = 10\n",
    "D, I = faiss_index.search(query_vec, k)\n",
    "\n",
    "# Step 7: Retrieve matching titles\n",
    "top_titles = [vault[titles[i]]['title'] for i in I[0]]\n",
    "print(f\"Top {k} similar notes to '{query}':\\n\")\n",
    "for idx, title in enumerate(top_titles, 1):\n",
    "    print(f\"{idx}. {title}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
