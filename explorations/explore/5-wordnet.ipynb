{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906901f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\RhysL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bb219a",
   "metadata": {},
   "source": [
    "### 2. Select Two Words\n",
    "\n",
    "Let’s use:\n",
    "\n",
    "\"car\"\n",
    "\n",
    "\"automobile\"\n",
    "\n",
    "These words are known to be synonyms. We can explore their synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124c2dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car synsets:\n",
      "car.n.01: a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "car.n.02: a wheeled vehicle adapted to the rails of railroad\n",
      "car.n.03: the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant\n",
      "car.n.04: where passengers ride up and down\n",
      "cable_car.n.01: a conveyance for passengers or freight on a cable railway\n",
      "\n",
      "Automobile synsets:\n",
      "car.n.01: a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "automobile.v.01: travel in an automobile\n"
     ]
    }
   ],
   "source": [
    "word1 = 'car'\n",
    "word2 = 'automobile'\n",
    "\n",
    "synsets_car = wn.synsets(word1)\n",
    "synsets_auto = wn.synsets(word2)\n",
    "\n",
    "print(\"Car synsets:\")\n",
    "for s in synsets_car:\n",
    "    print(f\"{s.name()}: {s.definition()}\")\n",
    "\n",
    "print(\"\\nAutomobile synsets:\")\n",
    "for s in synsets_auto:\n",
    "    print(f\"{s.name()}: {s.definition()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b058bf6",
   "metadata": {},
   "source": [
    "### 3. Check for Synonymy\n",
    "\n",
    "Let’s check if they share the same synset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f107b07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common synsets between 'car' and 'automobile':\n",
      "car.n.01 - a motor vehicle with four wheels; usually propelled by an internal combustion engine\n"
     ]
    }
   ],
   "source": [
    "# Check intersection\n",
    "common_synsets = set(synsets_car).intersection(synsets_auto)\n",
    "print(\"Common synsets between 'car' and 'automobile':\")\n",
    "for syn in common_synsets:\n",
    "    print(f\"{syn.name()} - {syn.definition()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e4eb4d",
   "metadata": {},
   "source": [
    "### 4. Explore Hypernyms and Hyponyms\n",
    "\n",
    "This shows that:\n",
    "\n",
    "A hypernym of \"car\" is \"motor_vehicle\".\n",
    "\n",
    "Some hyponyms include \"cab\", \"limousine\", and \"sports_car\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b612f52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernyms of 'car.n.01':\n",
      "motor_vehicle.n.01 - a self-propelled wheeled vehicle that does not run on rails\n",
      "\n",
      "Hyponyms of 'car.n.01':\n",
      "ambulance.n.01 - a vehicle that takes people to and from hospitals\n",
      "roadster.n.01 - an open automobile having a front seat and a rumble seat\n",
      "convertible.n.01 - a car that has top that can be folded or removed\n",
      "gas_guzzler.n.01 - a car with relatively low fuel efficiency\n",
      "subcompact.n.01 - a car smaller than a compact car\n",
      "\n",
      "Root hypernyms of 'car.n.01':\n",
      "entity.n.01 - that which is perceived or known or inferred to have its own distinct existence (living or nonliving)\n"
     ]
    }
   ],
   "source": [
    "car_synset = wn.synset('car.n.01')\n",
    "\n",
    "print(\"Hypernyms of 'car.n.01':\")\n",
    "for h in car_synset.hypernyms():\n",
    "    print(f\"{h.name()} - {h.definition()}\")\n",
    "\n",
    "print(\"\\nHyponyms of 'car.n.01':\")\n",
    "for h in car_synset.hyponyms()[:5]:  # limiting to 5\n",
    "    print(f\"{h.name()} - {h.definition()}\")\n",
    "\n",
    "print(\"\\nRoot hypernyms of 'car.n.01':\")\n",
    "for h in car_synset.root_hypernyms():\n",
    "    print(f\"{h.name()} - {h.definition()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf30747",
   "metadata": {},
   "source": [
    "### 5. Semantic Similarity\n",
    "Let’s measure how similar two concepts are using path similarity.\n",
    "This returns a score between 0 and 1:\n",
    "\n",
    "1.0 → identical synsets\n",
    "\n",
    "Lower values → more distant concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d833d3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path similarity between 'car' and 'bus': 0.125\n"
     ]
    }
   ],
   "source": [
    "car_syn = wn.synset('car.n.01')\n",
    "bus_syn = wn.synset('bus.n.01')  # another type of vehicle\n",
    "\n",
    "similarity = car_syn.path_similarity(bus_syn)\n",
    "print(f\"Path similarity between 'car' and 'bus': {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c264a1",
   "metadata": {},
   "source": [
    "# Tags and TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab002a9b",
   "metadata": {},
   "source": [
    "We are identifying which tags are **most semantically similar** to a set of high TF-IDF keywords by:\n",
    "\n",
    "1. **Decomposing compound tags** (e.g., `model_explainability` → `[\"model\", \"explainability\"]`).\n",
    "2. **Retrieving WordNet synsets** for both keywords and tag components.\n",
    "3. **Computing path-based semantic similarity** between each keyword and all components of each tag.\n",
    "4. **Storing the highest similarity score** for each keyword–tag pair.\n",
    "\n",
    "This allows us to later **rank tags** based on how semantically related they are to the most important words in a document.  \n",
    "#NLP #model_explainability #analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4108b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "236954aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH=\"../Data/enhanced_vault_index.json\"\n",
    "# # read json file\n",
    "with open(OUTPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    vault_index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f0301b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_id=\"acid_transaction\"\n",
    "node_id=\"api_driven_microservices\"\n",
    "# node_id=\"attention_mechanism\"\n",
    "# node_id=\"active_learning\"\n",
    "\n",
    "node=vault_index[node_id]\n",
    "\n",
    "# Given keywords and their TF-IDF scores\n",
    "tfidf_terms = node[\"TFIDF_Score\"]\n",
    "\n",
    "# Tag stems (simplified representation of tags)\n",
    "tags = [\n",
    "    \"classifier\", \"regressor\", \"clustering\", \"deep_learning\", \"anomaly_detection\",\n",
    "    \"ml_process\", \"ml_optimisation\", \"model_explainability\", \"evaluation\",\n",
    "    \"model_algorithm\", \"model_architecture\",\n",
    "    \"data_cleaning\", \"data_transformation\", \"data_processing\", \"data_engineering\",\n",
    "    \"data_governance\", \"data_management\", \"data_quality\",\n",
    "    \"database\", \"database_design\", \"relational_database\", \"database_optimisation\",\n",
    "    \"data_storage\", \"data_modeling\",\n",
    "    \"event_driven\", \"data_orchestration\", \"data_streaming\", \"data_workflow\",\n",
    "    \"cloud_computing\", \"querying\", \"big_data\",\n",
    "    \"data_exploration\", \"communication\", \"data_visualization\", \"business_intelligence\",\n",
    "    \"software\", \"code_snippet\", \"software_architecture\",\n",
    "    \"statistics\", \"math\",\n",
    "    \"GenAI\", \"language_models\", \"NLP\",\n",
    "    \"career\", \"field\", \"question\", \"drafting\", \"business\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6683e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1: Helper to get synset for a word (first synset as proxy)\n",
    "def get_first_synset(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    return synsets[0] if synsets else None\n",
    "\n",
    "# --- STEP 2: Synsets for keywords\n",
    "keyword_synsets = {\n",
    "    word: get_first_synset(word) for word in tfidf_terms\n",
    "}\n",
    "\n",
    "# --- STEP 3: Decompose tags and get synsets for each part\n",
    "tag_word_map = {tag: tag.split('_') for tag in tags}\n",
    "tag_synsets = {\n",
    "    tag: [get_first_synset(word) for word in words if get_first_synset(word)]\n",
    "    for tag, words in tag_word_map.items()\n",
    "}\n",
    "\n",
    "# --- STEP 4: Compute semantic similarity between each keyword synset and all tag synsets\n",
    "similarity_scores = {}\n",
    "\n",
    "for kw, kw_syn in keyword_synsets.items():\n",
    "    if not kw_syn:\n",
    "        continue\n",
    "    for tag, synset_list in tag_synsets.items():\n",
    "        max_sim = 0\n",
    "        for tag_syn in synset_list:\n",
    "            sim = kw_syn.path_similarity(tag_syn)\n",
    "            if sim and sim > max_sim:\n",
    "                max_sim = sim\n",
    "        if max_sim > 0:\n",
    "            similarity_scores[(kw, tag)] = max_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ac7ccd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event_driven', np.float64(0.45555555555555555)),\n",
       " ('model_architecture', np.float64(0.4083333333333334)),\n",
       " ('software_architecture', np.float64(0.4083333333333334))]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate tag similarity by summing top N contributions\n",
    "tag_aggregate_scores = {}\n",
    "\n",
    "for (keyword, tag), sim in similarity_scores.items():\n",
    "    tag_aggregate_scores.setdefault(tag, []).append(sim)\n",
    "\n",
    "# Average top 3 similarities for each tag\n",
    "tag_avg_sim = {\n",
    "    tag: np.mean(sorted(sims, reverse=True)[:3])\n",
    "    for tag, sims in tag_aggregate_scores.items()\n",
    "}\n",
    "\n",
    "# Get top 3 tags\n",
    "top_3_tags = sorted(tag_avg_sim.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "top_3_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e952678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
