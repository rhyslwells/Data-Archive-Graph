{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486ec81c",
   "metadata": {},
   "source": [
    "### ✅ Goal with `vault_index.json`\n",
    "\n",
    "You want to use `vault_index.json` as a **structured representation of your Obsidian vault** to:\n",
    "\n",
    "1. **Explore** your notes as a graph — nodes are notes, edges are links.\n",
    "2. **Query** and extract relevant subgraphs based on vague prompts.\n",
    "3. **Use an LLM** to:\n",
    "   - Interpret vague user input\n",
    "   - Identify relevant notes, tags, and links (subgraph)\n",
    "   - Generate questions or summaries from the selected subgraph\n",
    "4. **Feed selected notes into downstream prompts** for content generation, idea development, or question formulation.\n",
    "\n",
    "Optional: you’re interested in experimenting with this interactively in a **Jupyter notebook**, including visualisation, semantic search, and prompt composition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a96b6",
   "metadata": {},
   "source": [
    "Ideas for Additional Experiments\n",
    "Task\tGoal\n",
    "Centrality ranking\tRank notes that are most connected\n",
    "Clustering\tCluster notes by content similarity or tags\n",
    "Temporal views\tSort by last-modified (if tracked)\n",
    "Prompt tuning\tUse note summaries to improve LLM prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b735d",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857525e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 795 notes from vault_index.json\n",
      "1-on-1_template: ['title', 'path', 'tags', 'aliases', 'outlinks', 'inlinks', 'summary']\n",
      "ab_testing: ['title', 'path', 'tags', 'aliases', 'outlinks', 'inlinks', 'summary']\n",
      "accessing_gen_ai_generated_content: ['title', 'path', 'tags', 'aliases', 'outlinks', 'inlinks', 'summary']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# LOAD AND INSPECT THE VAULT INDEX\n",
    "# ============================================\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the vault index\n",
    "with open(\"vault_index.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    vault = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0269c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded {len(vault)} notes from vault_index.json\")\n",
    "# Preview a few entries\n",
    "for i, (k, v) in enumerate(vault.items()):\n",
    "    print(f\"{k}: {list(v.keys())}\")\n",
    "    if i == 2: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d394182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conceptual_data_model\n",
      "conceptual_model\n",
      "concurrency\n",
      "confidence_interval\n",
      "confusion_matrix\n"
     ]
    }
   ],
   "source": [
    "for i in [title for title in vault.keys()][100:105]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b271269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'conceptual data model',\n",
       " 'path': 'C:\\\\Users\\\\RhysL\\\\Desktop\\\\Data-Archive\\\\content\\\\standardised\\\\conceptual data model.md',\n",
       " 'tags': [],\n",
       " 'aliases': [],\n",
       " 'outlinks': [],\n",
       " 'inlinks': ['database_schema'],\n",
       " 'summary': ''}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title1=\"conceptual_data_model\"\n",
    "vault[title1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9062359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': None,\n",
       " 'path': 'C:\\\\Users\\\\RhysL\\\\Desktop\\\\Data-Archive\\\\content\\\\standardised\\\\Confusion Matrix.md',\n",
       " 'tags': ['evaluation'],\n",
       " 'aliases': None,\n",
       " 'outlinks': ['Classification',\n",
       "  'Pasted image 20240120215414.png',\n",
       "  'Accuracy',\n",
       "  'Precision',\n",
       "  'Recall',\n",
       "  'F1 Score',\n",
       "  'Specificity',\n",
       "  'Recall',\n",
       "  'Pasted image 20240116205937.png|500',\n",
       "  'Pasted image 20240116210541.png|500'],\n",
       " 'inlinks': ['accuracy', 'evaluation_metrics', 'logistic_regression'],\n",
       " 'summary': 'Description A Confusion Matrix is a table used to evaluate the performance of a [[Classification]] model. It provides a detailed breakdown of the model\\'s predictions across different classes, showing the number of true positives, true negatives, false positives, and false negatives. Purpose The confusion matrix helps identify where the classifier is making errors, indicating where it is \"confused\" in its predictions. Structure ![[Pasted image 20240120215414.png]] Structure True Positives (TP): Correctly predicted positive instances. False Positives (FP): Incorrectly predicted positive instances (Type 1 error). True Negatives (TN): Correctly predicted negative instances. False Negatives (FN): Incorrectly predicted negative instances (Type 2 error)....'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title2=\"confusion_matrix\"\n",
    "vault[title2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7400e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================\n",
    "# BASIC TAG AND LINK STATS\n",
    "# ============================================\n",
    "\n",
    "# Identify notes with few or no links (potential orphans)\n",
    "\n",
    "\n",
    "# Count tag frequencies\n",
    "tag_counts = Counter(tag for note in vault.values() for tag in note.get(\"tags\", []))\n",
    "print(\"\\nTop 10 Tags:\")\n",
    "for tag, count in tag_counts.most_common(10):\n",
    "    print(f\"{tag}: {count}\")\n",
    "\n",
    "# Find orphan notes (no inlinks or outlinks)\n",
    "orphans = [\n",
    "    title for title, note in vault.items()\n",
    "    if not note.get(\"outlinks\") and all(title not in n.get(\"outlinks\", []) for n in vault.values())\n",
    "]\n",
    "print(f\"\\nNumber of orphan notes: {len(orphans)}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# CONSTRUCT A DIRECTED LINK GRAPH\n",
    "# ============================================\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges\n",
    "for title, note in vault.items():\n",
    "    G.add_node(title, tags=note.get(\"tags\", []))\n",
    "    for outlink in note.get(\"outlinks\", []):\n",
    "        if outlink in vault:  # only if target exists\n",
    "            G.add_edge(title, outlink)\n",
    "\n",
    "print(f\"\\nGraph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# VISUALIZE THE FULL GRAPH (small vaults only)\n",
    "# ============================================\n",
    "\n",
    "def plot_graph(graph, figsize=(12, 8), label_nodes=False):\n",
    "    plt.figure(figsize=figsize)\n",
    "    pos = nx.spring_layout(graph, k=0.5, seed=42)\n",
    "    nx.draw(graph, pos, node_size=30, edge_color='gray', alpha=0.6)\n",
    "    if label_nodes:\n",
    "        nx.draw_networkx_labels(graph, pos, font_size=8)\n",
    "    plt.title(\"Obsidian Vault Graph\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Warning: avoid for large graphs\n",
    "# plot_graph(G, label_nodes=False)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# EXTRACT A SUBGRAPH BY TITLE + DEPTH\n",
    "# ============================================\n",
    "\n",
    "def get_subgraph(center_title, depth=1):\n",
    "    if center_title not in G:\n",
    "        print(f\"'{center_title}' not found in graph.\")\n",
    "        return None\n",
    "    sub = nx.ego_graph(G, center_title, radius=depth, directed=True)\n",
    "    print(f\"Subgraph has {len(sub)} nodes\")\n",
    "    return sub\n",
    "\n",
    "# Example: a 1-hop neighborhood\n",
    "subG = get_subgraph(\"Bayesian Uncertainty\", depth=1)\n",
    "plot_graph(subG, label_nodes=True)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# PROMPT PREPARATION FOR TOP-N NOTES\n",
    "# ============================================\n",
    "\n",
    "def build_prompt(note_titles, vault):\n",
    "    prompt = \"\"\n",
    "    for t in note_titles:\n",
    "        note = vault.get(t, {})\n",
    "        prompt += f\"# {t}\\n\"\n",
    "        prompt += f\"Tags: {', '.join(note.get('tags', []))}\\n\"\n",
    "        prompt += note.get(\"content\", \"\")[:500] + \"\\n\\n\"\n",
    "    return prompt\n",
    "\n",
    "# Example usage\n",
    "example_titles = list(subG.nodes)[:3]\n",
    "prompt_text = build_prompt(example_titles, vault)\n",
    "print(prompt_text)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# OPTIONAL: RANK NOTES BY CENTRALITY\n",
    "# ============================================\n",
    "\n",
    "centrality = nx.degree_centrality(G)\n",
    "top_nodes = sorted(centrality.items(), key=lambda x: -x[1])[:10]\n",
    "print(\"\\nTop 10 central notes:\")\n",
    "for t, score in top_nodes:\n",
    "    print(f\"{t}: {score:.3f}\")\n",
    "\n",
    "#-----------------------\n",
    "4. Search Notes by Concept or Similarity #ml #NLP\n",
    "With embeddings added:\n",
    "\n",
    "Load embedding index (e.g. FAISS)\n",
    "\n",
    "Perform semantic search from question prompt\n",
    "\n",
    "Return top-K relevant notes from the vault\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "# Assuming you’ve built a FAISS index keyed by title\n",
    "query_vec = model.encode(\"Uncertainty quantification\")\n",
    "D, I = faiss_index.search(np.array([query_vec]), k=5)\n",
    "top_titles = [titles[i] for i in I[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0714e0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
